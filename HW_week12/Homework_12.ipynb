{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "0c3c5b70-e7f1-447b-acd6-91e6cb67881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "82ffb4b2-6a6b-4d05-88e0-f4bba2f57b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df= pd.read_csv('train.csv')\n",
    "#titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "863c779f-b8a1-409b-bbd4-845728c72731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "4f3595b7-6c4e-4681-9673-9cb340faa676",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Age'].fillna(titanic_df['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "dc570aa9-294d-4563-a260-e14a75b0b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "843ace45-66b1-429b-a84e-ba7c25dd8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "fa68e89c-c1a8-409a-9ae9-f19f982b1c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.drop(['Cabin'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "b734756f-0a0a-4d9a-8de9-d25be2e07529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f3fcf693-b4d3-446d-a447-0208133e208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical features to be scaled\n",
    "numerical_features = ['Age', 'Fare']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical features\n",
    "titanic_df[numerical_features] = scaler.fit_transform(titanic_df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "3b84d849-9462-4c16-b3fc-069c368273b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "fb53501c-daa6-4c5f-90d1-b7b66d12e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features: Sex and Embarked\n",
    "encoder = OneHotEncoder(drop='first') \n",
    "encoded_features = encoder.fit_transform(titanic_df[['Sex', 'Embarked']]).toarray()\n",
    "\n",
    "# Create column names for the encoded features\n",
    "encoded_columns = encoder.get_feature_names_out(['Sex', 'Embarked'])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with the original dataframe\n",
    "titanic_df = pd.concat([titanic_df, encoded_df], axis=1)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "titanic_df.drop(['Sex', 'Embarked'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d76fcf2d-1beb-4834-b6f5-0faad9356b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(titanic_df[['Age', 'Fare']])\n",
    "titanic_df['PCA1'] = principal_components[:, 0]\n",
    "titanic_df['PCA2'] = principal_components[:, 1]\n",
    "titanic_df.drop(['Age', 'Fare'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "cfafdde7-eda4-46cb-a8da-e2bb8bf65aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = titanic_df.drop(['Survived', 'Name', 'Ticket'], axis=1)\n",
    "y = titanic_df['Survived']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d5cf26cb-506b-4da1-b176-dd3f5d7ebd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357a59fe-53f8-416e-bae9-84b96e5e4d04",
   "metadata": {},
   "source": [
    "# naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b451da1c-e7a8-40a6-a255-e013bbebe4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.7597765363128491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "print(f'Naive Bayes Accuracy: {nb_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd59e6-7cc1-4e23-85aa-6ecdfa17921e",
   "metadata": {},
   "source": [
    "# Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ab3916dc-33da-4e2e-a9ce-bc4688e21117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=500)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "logreg_predictions = logreg_model.predict(X_test)\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_predictions)\n",
    "print(f'Logistic Regression Accuracy: {logreg_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ec3c6-7693-4998-9e76-02176fd6ece8",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c16e8834-ea07-425d-a349-a2c9c9fd1816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5865921787709497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(f'SVM Accuracy: {svm_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e7fd0-d11e-4f94-94d5-45bc2542f9e0",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7fcd38f8-4c62-476e-bd69-43d9d9d3adaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "c8ca4248-c936-44fd-be60-a90ce8f1f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loading test.csv and preprocessing\n",
    "Z_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "Z_test.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "Z_test['Age'].fillna(Z_test['Age'].median(), inplace=True)\n",
    "Z_test['Embarked'].fillna(Z_test['Embarked'].mode()[0], inplace=True)\n",
    "Z_test['Fare'].fillna(Z_test['Fare'].median(), inplace=True)\n",
    "\n",
    "# Identify numerical features to be scaled\n",
    "numerical_features = ['Age', 'Fare']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical features\n",
    "Z_test[numerical_features] = scaler.fit_transform(Z_test[numerical_features])\n",
    "\n",
    "# Encode categorical features: Sex and Embarked\n",
    "encoder = OneHotEncoder(drop='first')  # drop='first' to avoid multicollinearity\n",
    "encoded_features = encoder.fit_transform(Z_test[['Sex', 'Embarked']]).toarray()\n",
    "\n",
    "# Create column names for the encoded features\n",
    "encoded_columns = encoder.get_feature_names_out(['Sex', 'Embarked'])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoded_columns)\n",
    "\n",
    "# Concatenate encoded features with the original dataframe\n",
    "Z_test = pd.concat([Z_test, encoded_df], axis=1)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "Z_test.drop(['Sex', 'Embarked'], axis=1, inplace=True)\n",
    "\n",
    "# Apply PCA to reduce dimensionality (optional)\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(Z_test[['Age', 'Fare']])\n",
    "Z_test['PCA1'] = principal_components[:, 0]\n",
    "Z_test['PCA2'] = principal_components[:, 1]\n",
    "Z_test.drop(['Age', 'Fare'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ba253842-566c-4960-b2ff-ca2ce366232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b9629891-1b3a-4540-b76d-e8705be7a402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = rf_model.predict(Z_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "74b3bf68-3c6b-48a4-adeb-9876ff52e560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully.\n"
     ]
    }
   ],
   "source": [
    "#creating dataframe to contain passenger id and survived status for test.csv(Z_test)\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': Z_test['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "# Export to CSV\n",
    "submission_df.to_csv('Kaggle_sub.csv', index=False)\n",
    "print(\"Submission file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105b39c-7530-4319-a6b2-f226cdd5d6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
